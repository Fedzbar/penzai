{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "V28",
      "collapsed_sections": [
        "EDxSRwBfaIk4",
        "sQRfBOh-eRTu"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Inspecting and Patching Gemma With Penzai - ICLR 2024\n"
      ],
      "metadata": {
        "id": "sVy2tIhgZ3UE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Penzai is a JAX research toolkit for building, editing, and visualizing neural networks. This demo shows how to use it to inspect and patch the Gemma open-weights models. (Want a more in-depth tutorial? Check out the [Penzai documentation](https://penzai.readthedocs.io/)!)\n",
        "\n",
        "You can follow along yourself using your own copy of this notebook:\n",
        "\n",
        "- To load Gemma 2B, you can use either a **\"TPU v2\"** or **\"T4 GPU\"** Colab runtime.\n",
        "  - TPU v2 is recommended. If you use a T4 GPU runtime, it may run out of memory in Part D of the demo.\n",
        "- To load Gemma 7B, you'll need to connect to a **\"TPU v2\"** Colab runtime.\n",
        "\n",
        "You can change your runtime type using the \"Runtime\" menu at the top of Colab."
      ],
      "metadata": {
        "id": "Gmk7F9M6aRjx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before you start, you'll also need to:\n",
        "\n",
        "- Sign up for a Kaggle account at  https://www.kaggle.com/ if you don't have one already\n",
        "- Consent to the Gemma Terms of Use at https://www.kaggle.com/models/google/gemma/license/consent\n",
        "- Generate a Kaggle API key:\n",
        "  - Go to your account settings (https://www.kaggle.com/settings), then the ‘API’ section.\n",
        "  - Click ‘Create new token’ to download your key.\n"
      ],
      "metadata": {
        "id": "N1S2JKCngEhs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting up"
      ],
      "metadata": {
        "id": "F5vjDGCbfdgV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Connecting to Kaggle"
      ],
      "metadata": {
        "id": "aE-k6c8Yf2Rc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the cell below, then enter your username and Kaggle API key (from https://www.kaggle.com/settings):"
      ],
      "metadata": {
        "id": "ElozCXCKfit4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "kagglehub.login()"
      ],
      "metadata": {
        "id": "kmBPBQmJcqNg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You should see \"Kaggle credentials successfully validated.\""
      ],
      "metadata": {
        "id": "BIVz0gwC2gj2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next select which model you want to use, based on the Colab runtime you are connected to:"
      ],
      "metadata": {
        "id": "gnIuRnPvdWOl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_choice = \"Gemma 2B (any accelerator kernel)\" # @param [\"Gemma 7B (for TPU v2 kernel)\", \"Gemma 2B (any accelerator kernel)\"]"
      ],
      "metadata": {
        "id": "3K-kRSQJdJD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports and Configuration\n",
        "\n",
        "Running these cells will install Penzai in your runtime and set it up as the default pretty-printer."
      ],
      "metadata": {
        "id": "EDxSRwBfaIk4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iog3oMAMGCMG"
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A6PfRdZHQVYm"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  import penzai\n",
        "except ImportError:\n",
        "  !pip install \"penzai[notebook]>=0.1.1,<0.2\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v26wYYx6QSn3"
      },
      "outputs": [],
      "source": [
        "from typing import Any, Callable\n",
        "import dataclasses\n",
        "import os\n",
        "import traceback\n",
        "import gc\n",
        "import collections\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import numpy as np\n",
        "import orbax.checkpoint\n",
        "import optax\n",
        "from jax.experimental import mesh_utils\n",
        "import sentencepiece as spm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Allow using ~all GPU memory if using a Colab GPU kernel.\n",
        "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \".98\""
      ],
      "metadata": {
        "id": "zwe2XU_8Zn9h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Mh2mAuiQ4aa"
      },
      "outputs": [],
      "source": [
        "import penzai\n",
        "from penzai import pz\n",
        "from penzai.example_models import gemma\n",
        "from penzai.toolshed import basic_training\n",
        "from penzai.toolshed import token_visualization\n",
        "from penzai.toolshed import jit_wrapper\n",
        "from penzai.toolshed import lora\n",
        "from penzai.toolshed import auto_nmap\n",
        "from penzai.toolshed import model_rewiring"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nx_jax = auto_nmap.wrap_module(jax)\n",
        "nx_jnp = auto_nmap.wrap_module(jnp)"
      ],
      "metadata": {
        "id": "hclUe-w5i1_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YodWk_jmva_7"
      },
      "outputs": [],
      "source": [
        "pz.ts.register_as_default()\n",
        "pz.ts.register_autovisualize_magic()\n",
        "pz.ts.register_context_manager_magic()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pz.enable_interactive_context()\n",
        "pz.ts.active_autovisualizer.set_interactive(pz.ts.ArrayAutovisualizer())"
      ],
      "metadata": {
        "id": "QbWgaSc7lGwx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading Gemma"
      ],
      "metadata": {
        "id": "6z2SGqnlaWxv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you added a Kaggle API key and agreed to the consent form, you can then load it as follows:"
      ],
      "metadata": {
        "id": "wRv4CC_odY7n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if model_choice.startswith(\"Gemma 7B\"):\n",
        "  model_variant = '7b'\n",
        "elif model_choice.startswith(\"Gemma 2B\"):\n",
        "  model_variant = '2b'\n",
        "else:\n",
        "  raise NotImplementedError()\n",
        "\n",
        "weights_dir = kagglehub.model_download(f\"google/gemma/Flax/{model_variant}\")\n",
        "ckpt_path = os.path.join(weights_dir, model_variant)\n",
        "vocab_path = os.path.join(weights_dir, 'tokenizer.model')"
      ],
      "metadata": {
        "id": "79-NVMoXdfsZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pEXnGmeUGxCK"
      },
      "outputs": [],
      "source": [
        "vocab = spm.SentencePieceProcessor()\n",
        "vocab.Load(vocab_path)\n",
        "checkpointer = orbax.checkpoint.PyTreeCheckpointer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NmHhvp0ixosC"
      },
      "outputs": [],
      "source": [
        "metadata = checkpointer.metadata(ckpt_path)\n",
        "n_devices = jax.local_device_count()\n",
        "sharding_devices = mesh_utils.create_device_mesh((n_devices,))\n",
        "sharding = jax.sharding.PositionalSharding(sharding_devices)\n",
        "restore_args = jax.tree_util.tree_map(\n",
        "    lambda m: orbax.checkpoint.ArrayRestoreArgs(\n",
        "        restore_type=jax.Array,\n",
        "        sharding=sharding.reshape((1,) * (len(m.shape) - 1) + (n_devices,))\n",
        "    ),\n",
        "    metadata,\n",
        ")\n",
        "flat_params = checkpointer.restore(ckpt_path, restore_args=restore_args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g9amupev6WKj"
      },
      "outputs": [],
      "source": [
        "gemma_model = gemma.model_core.GemmaTransformer.from_pretrained(\n",
        "    flat_params,\n",
        "    upcast_activations_to_float32=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Helper functions\n",
        "These cells define some helper functions that will be useful for interacting with Gemma."
      ],
      "metadata": {
        "id": "sQRfBOh-eRTu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_batch(examples, pad_length=32, include_eos=True):\n",
        "  padded_tokens = []\n",
        "  for example in examples:\n",
        "    example_tokens = [vocab.bos_id()] + vocab.EncodeAsIds(example)\n",
        "    if include_eos:\n",
        "      example_tokens = example_tokens + [vocab.eos_id()]\n",
        "    assert len(example_tokens) <= pad_length\n",
        "    example_tokens = example_tokens + [vocab.pad_id()] * (pad_length - len(example_tokens))\n",
        "    padded_tokens.append(example_tokens)\n",
        "  return pz.nx.wrap(jnp.array(padded_tokens)).tag(\"batch\", \"seq\")"
      ],
      "metadata": {
        "id": "YeA2rE-OeYip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def xent_loss_fn(model, rng, state, input_examples):\n",
        "  del rng, state\n",
        "\n",
        "  outputs = model(gemma.model_core.GemmaInputs.from_basic_segments(\n",
        "      input_examples[{\"seq\": pz.slice[:-1]}]\n",
        "  ))\n",
        "  all_log_probs = pz.nx.nmap(jax.nn.log_softmax)(\n",
        "      outputs.untag(\"vocabulary\")\n",
        "  ).tag(\"vocabulary\")\n",
        "\n",
        "  correct_next_tokens = input_examples[{\"seq\": pz.slice[1:]}]\n",
        "  correct_log_probs = pz.nx.nmap(jnp.where)(\n",
        "      correct_next_tokens == vocab.pad_id(),\n",
        "      0.0,\n",
        "      all_log_probs[{\"vocabulary\": correct_next_tokens}],\n",
        "  )\n",
        "\n",
        "  loss = -correct_log_probs.untag(\"batch\", \"seq\").unwrap().mean()\n",
        "  return loss, None, {\"loss\": loss}"
      ],
      "metadata": {
        "id": "wgd6ZE3SovVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xent_loss_train_step = basic_training.build_train_step_fn(\n",
        "    xent_loss_fn, donate_params_and_state=True\n",
        ")"
      ],
      "metadata": {
        "id": "twGd_I911gK3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Demo Part A: Visualizing and running the model"
      ],
      "metadata": {
        "id": "kFvxhBGCe68W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Show the model:\n",
        "gemma_model"
      ],
      "metadata": {
        "id": "V60oHDx_e9T3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize some text:\n",
        "tokens = [\n",
        "    \"Penzai includes a number of general-purpose tools for analyzing JAX neural networks.\",\n",
        "    \"It also includes a declarative neural-network library designed to take advantage of those tools.\",\n",
        "]\n",
        "tokenized_prompts = tokenize_batch(tokens, 32, include_eos=True)"
      ],
      "metadata": {
        "id": "3-5POpNkiTfY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show the tokens\n",
        "%%autovisualize pz.ts.ArrayAutovisualizer.for_tokenizer(vocab)\n",
        "tokenized_prompts"
      ],
      "metadata": {
        "id": "puyVRQyFiX74"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the model on the tokens:\n",
        "example_input = gemma.model_core.GemmaInputs.from_basic_segments(tokenized_prompts)\n",
        "output = gemma_model(example_input)\n",
        "output"
      ],
      "metadata": {
        "id": "bQqgLUNwicv6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute probabilities:\n",
        "nx_jax.nn.softmax(output.untag(\"vocabulary\")).tag(\"vocabulary\")"
      ],
      "metadata": {
        "id": "oSYORS-Kimu7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To extract part of a model, click a \"copy path\" button...\n",
        "accessor_fn = REPLACE_ME # <- ...then paste it here\n",
        "\n",
        "layer = accessor_fn(gemma_model)\n",
        "layer"
      ],
      "metadata": {
        "id": "pDrxDdt6jDou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Call it on an appropriately-sized input:\n",
        "# (Assuming you copied a query/key/value projection layer, you can use an\n",
        "# embedding size of 2048 for the 2B model or 3072 for the 7B model.)\n",
        "layer(pz.nx.ones({\"embedding\": 2048}))"
      ],
      "metadata": {
        "id": "7LuT9T7XjmRI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Try clicking the pretty-printed output, above, pressing \"r\" for roundtrip\n",
        "# mode, then copying and pasting that output below:\n",
        "\n"
      ],
      "metadata": {
        "id": "auX8teOrjxJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Demo Part B: Inspecting model intermediate values"
      ],
      "metadata": {
        "id": "AV2XwHhve_rn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select all softmax operations:\n",
        "(\n",
        "    pz.select(gemma_model)\n",
        "    .at_instances_of(gemma.model_core.GemmaAttention)\n",
        "    .at_instances_of(pz.nn.Softmax)\n",
        ")"
      ],
      "metadata": {
        "id": "0JeRmA4FfHF0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Insert new logic:\n",
        "\n",
        "@pz.pytree_dataclass\n",
        "class ShowValue(pz.Layer):\n",
        "  def __call__(self, x):\n",
        "    print(\"My intermediate value:\", x)\n",
        "    return x\n",
        "\n",
        "verbose_model = (\n",
        "    pz.select(gemma_model)\n",
        "    .at_instances_of(gemma.model_core.GemmaAttention)\n",
        "    .at_instances_of(pz.nn.Softmax)\n",
        "    .insert_after(ShowValue())\n",
        ")"
      ],
      "metadata": {
        "id": "4YadefEFeEkm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check what you've inserted by printing it out:\n",
        "verbose_model"
      ],
      "metadata": {
        "id": "V4-69iIykwbN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run it:\n",
        "verbose_model(example_input)"
      ],
      "metadata": {
        "id": "MK7u1r7Lk2Su"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# New input sequence (because repeating text has more interesting patterns)\n",
        "example_text = (\n",
        "    \"Penzai: A JAX research toolkit for building, editing, and visualizing neural networks.\"\n",
        "    + \" \" + \"Penzai: A JAX research toolkit for building, editing, and visualizing neural networks.\"\n",
        ")\n",
        "tokens = jnp.array([vocab.bos_id()] + vocab.EncodeAsIds(example_text))\n",
        "token_seq = pz.nx.wrap(tokens).tag(\"seq\")\n",
        "single_input = gemma.model_core.GemmaInputs.from_basic_segments(token_seq)"
      ],
      "metadata": {
        "id": "zk-5V9nqk6Y_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract intermediate values:\n",
        "side_output_model = pz.de.CollectingSideOutputs.handling(\n",
        "    pz.select(gemma_model)\n",
        "    .at_instances_of(gemma.model_core.GemmaAttention)\n",
        "    .at_instances_of(pz.nn.Softmax)\n",
        "    .insert_after(pz.de.TellIntermediate())\n",
        ")\n",
        "\n",
        "_, side_outs = side_output_model(single_input)\n",
        "all_attentions = pz.nx.stack(\n",
        "    [out.value for out in side_outs],\n",
        "    \"blocks\",\n",
        ")"
      ],
      "metadata": {
        "id": "AruD6lLElMmZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize them:\n",
        "tok_strs = [repr(vocab.IdToPiece(int(t))) for t in tokens]\n",
        "pz.ts.render_array(\n",
        "    all_attentions,\n",
        "    axis_item_labels={\"seq\": tok_strs, \"kv_seq\": tok_strs},\n",
        "    rows=[\"seq\", \"blocks\"], columns=[\"kv_seq\", \"heads\"],\n",
        "    valid_mask=single_input.attention_mask,\n",
        ")"
      ],
      "metadata": {
        "id": "Gs1x5gXflXuq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Demo Part C: Modifying intermediate values"
      ],
      "metadata": {
        "id": "O00aSc2XhWpF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Some input text: A repeated sequence of otherwise-unpredictable digits.\n",
        "example_text = (\n",
        "    \"01976954310149754605\"\n",
        "    + \"01976954310149754605\"\n",
        ")\n",
        "tokens = jnp.array([vocab.bos_id()] + vocab.EncodeAsIds(example_text))\n",
        "token_seq = pz.nx.wrap(tokens).tag(\"seq\")\n",
        "single_input = gemma.model_core.GemmaInputs.from_basic_segments(token_seq)"
      ],
      "metadata": {
        "id": "KrR10ne8hmMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Score them under the model:\n",
        "logits = gemma_model(single_input)\n",
        "log_probs = nx_jax.nn.log_softmax(logits.untag(\"vocabulary\")).tag(\"vocabulary\")\n",
        "sliced_preds = log_probs[{\"seq\": pz.slice[:-1]}]\n",
        "correct_next_token = token_seq[{\"seq\": pz.slice[1:]}]\n",
        "log_prob_of_correct_next = sliced_preds[{\"vocabulary\": correct_next_token}]\n",
        "token_visualization.show_token_scores(\n",
        "    correct_next_token, nx_jnp.exp(log_prob_of_correct_next), vocab, vmax=1\n",
        ")"
      ],
      "metadata": {
        "id": "IsRNJa_4mndL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify a specific subset of heads\n",
        "# (see https://penzai.readthedocs.io/en/stable/notebooks/induction_heads.html)\n",
        "if model_choice.startswith(\"Gemma 7B\"):\n",
        "  mask_shape = (28, 16)\n",
        "  block_indices = jnp.array([5,14,20,21,21,21])\n",
        "  head_indices = jnp.array([0,15,13,1,2,5])\n",
        "elif model_choice.startswith(\"Gemma 2B\"):\n",
        "  mask_shape = (18, 8)\n",
        "  block_indices = jnp.array([11,14,14])\n",
        "  head_indices = jnp.array([3,0,4])\n",
        "else:\n",
        "  raise NotImplementedError()\n",
        "\n",
        "top_heads_mask = pz.nx.wrap(\n",
        "    jnp.ones(mask_shape).at[block_indices, head_indices].set(0.0)\n",
        ").tag(\"blocks\", \"heads\")\n",
        "top_heads_mask"
      ],
      "metadata": {
        "id": "LzED0CkenKi7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Knock them out:\n",
        "def knock_out_heads(model, head_mask_per_block):\n",
        "  parts = list(head_mask_per_block.untag(\"blocks\"))\n",
        "  return (\n",
        "      pz.select(model)\n",
        "      .at_instances_of(gemma.model_core.GemmaAttention)\n",
        "      .at_instances_of(pz.nn.Softmax)\n",
        "      .insert_after(\"<placeholder>\", and_select=True)\n",
        "      .set_sequence(\n",
        "          model_rewiring.KnockOutAttentionHeads(part) for part in parts\n",
        "      )\n",
        "  )\n",
        "\n",
        "knockout_model = knock_out_heads(gemma_model, top_heads_mask)"
      ],
      "metadata": {
        "id": "iBTKfuE5m0bb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the knocked-out model:\n",
        "logits = knockout_model(single_input)\n",
        "\n",
        "# Result: Much less confident and less accurate predictions!\n",
        "log_probs = pz.nx.nmap(jax.nn.log_softmax)(logits.untag(\"vocabulary\")).tag(\"vocabulary\")\n",
        "sliced_preds = log_probs[{\"seq\": pz.slice[:-1]}]\n",
        "correct_next_token = token_seq[{\"seq\": pz.slice[1:]}]\n",
        "log_prob_of_correct_next = sliced_preds[{\"vocabulary\": correct_next_token}]\n",
        "token_visualization.show_token_scores(correct_next_token, pz.nx.nmap(jnp.exp)(log_prob_of_correct_next), vocab, vmax=1)"
      ],
      "metadata": {
        "id": "H2OqIfX111ee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Demo Part D: Low-rank Finetuning and Sampling"
      ],
      "metadata": {
        "id": "VlDQ5ipdhmqE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Freeze the existing weights.\n",
        "frozen_gemma_model = (\n",
        "    pz.select(gemma_model)\n",
        "    .at_instances_of(pz.nn.Parameter)\n",
        "    .apply(\n",
        "        lambda param: pz.nn.FrozenParameter(param.value, param.name)\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "EKiBUxiqBpTz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace linear layers with low-rank adapter layers:\n",
        "lora_model_def = (\n",
        "    pz.select(frozen_gemma_model)\n",
        "    .at_instances_of(gemma.model_core.GemmaAttention)\n",
        "    .at_instances_of(pz.nn.Linear)\n",
        "    .apply(\n",
        "        lambda k, layer: lora.LowRankAdapter.from_linear(\n",
        "            layer, rank=16, name=jax.tree_util.keystr(k)\n",
        "        ),\n",
        "        with_keypath=True\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "A-TqieUQB3eU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the new parameters:\n",
        "lora_model = pz.nn.initialize_parameters(lora_model_def, jax.random.key(10))"
      ],
      "metadata": {
        "id": "bEfig1FHB56-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Look at it:\n",
        "lora_model"
      ],
      "metadata": {
        "id": "46XmBLkfod2C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train it on a synthetic task:\n",
        "def generate_example(np_rng):\n",
        "  a, b = np_rng.choice(1000, size=(2,))\n",
        "  return f\">>> mystery_function({a}, {b})\\n{a + b}\""
      ],
      "metadata": {
        "id": "ok_gCVDSogtZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h0zIaz4hD_yI"
      },
      "outputs": [],
      "source": [
        "train_state = basic_training.TrainState.initial_state(\n",
        "    model=lora_model,\n",
        "    optimizer_def=optax.adamw(5e-5, weight_decay=0.01),\n",
        "    root_rng=jax.random.key(42),\n",
        ")\n",
        "np_rng = np.random.default_rng(123)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W5Osnw8GD_yI"
      },
      "outputs": [],
      "source": [
        "while train_state.step < 200:\n",
        "  input_examples = tokenize_batch([\n",
        "      generate_example(np_rng) for _ in range(16)\n",
        "  ])\n",
        "  train_state, out = xent_loss_train_step(train_state, input_examples=input_examples)\n",
        "  if train_state.step % 10 == 0:\n",
        "    print(train_state.step, out)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert it to sampling mode:\n",
        "finetuned_inference_model, initial_inference_state = (\n",
        "  gemma.sampling_mode.GemmaKVCachingTransformer.from_uncached(\n",
        "      train_state.model,\n",
        "      cache_len=64,\n",
        "      batch_axes={\"batch\": 4},\n",
        "  )\n",
        ")"
      ],
      "metadata": {
        "id": "I2DWjJajo06b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make some prompts:\n",
        "prompts = [\n",
        "    \">>> mystery_function(123, 123)\",\n",
        "    \">>> mystery_function(101, 15)\",\n",
        "    \">>> mystery_function(999, 876)\",\n",
        "    \">>>\", # Let the model write and solve its own problem\n",
        "]"
      ],
      "metadata": {
        "id": "SQcAOJtBo9q1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%autovisualize pz.ts.ArrayAutovisualizer.for_tokenizer(vocab)\n",
        "tokenized_prompts = tokenize_batch(prompts, 16, include_eos=False)\n",
        "tokenized_prompts"
      ],
      "metadata": {
        "id": "K2jg6OOppC7i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Draw samples:\n",
        "samples = gemma.simple_decoding_loop.temperature_sample_pyloop(\n",
        "    jit_wrapper.Jitted(finetuned_inference_model),\n",
        "    initial_inference_state,\n",
        "    prompt=tokenized_prompts,\n",
        "    rng=jax.random.key(3),\n",
        "    pad_id=vocab.pad_id(),\n",
        "    max_sampling_steps=20,\n",
        ")"
      ],
      "metadata": {
        "id": "6fFV0gyepFJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# And visualize them:\n",
        "token_visualization.show_token_array(samples, vocab)"
      ],
      "metadata": {
        "id": "wfYW1kfIpMJ5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
